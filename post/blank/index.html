<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Skills and Scores</title>
  <meta property="og:title" content="Skills and Scores" />
  <meta name="twitter:title" content="Skills and Scores" />
  <meta name="description" content="My brother once told me: “Playing day 2 of a GP is like playing on the Pro Tour – probably even harder”. Neither of us had yet played at the Pro Tour nor made a GP day 2 at that time, but in place of experience we at least had deep respect for the GP day 2 player field. However, regardless of my brother’s statement being right or wrong (it was wrong), the underlying idea is interesting: It must be only the finest players, who are capable of winning at least seven of nine rounds of exhausting tournament Magic.">
  <meta property="og:description" content="My brother once told me: “Playing day 2 of a GP is like playing on the Pro Tour – probably even harder”. Neither of us had yet played at the Pro Tour nor made a GP day 2 at that time, but in place of experience we at least had deep respect for the GP day 2 player field. However, regardless of my brother’s statement being right or wrong (it was wrong), the underlying idea is interesting: It must be only the finest players, who are capable of winning at least seven of nine rounds of exhausting tournament Magic.">
  <meta name="twitter:description" content="My brother once told me: “Playing day 2 of a GP is like playing on the Pro Tour – probably even harder”. Neither of us had yet played at the Pro Tour nor made a GP day 2 at that time, but in place of …">
  <meta name="author" content="Felix Weidemann"/>
  <link href='https://mtganalyze.github.io/img/icon.ico' rel='icon' type='image/x-icon'/>
  <meta property="og:image" content="https://mtganalyze.github.io/img/theorist.jpg" />
  <meta name="twitter:image" content="https://mtganalyze.github.io/img/theorist.jpg" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@mtganalyze" />
  <meta name="twitter:creator" content="@mtganalyze" />
  <meta property="og:url" content="https://mtganalyze.github.io/post/blank/" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="MTGANALYZE" />

  <meta name="generator" content="Hugo 0.26" />
  <link rel="canonical" href="https://mtganalyze.github.io/post/blank/" />
  <link rel="alternate" href="https://mtganalyze.github.io/index.xml" type="application/rss+xml" title="MTGANALYZE">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css" integrity="sha384-wITovz90syo1dJWVh32uuETPVEtGigN07tkttEqPv+uR2SE/mbQcG7ATL28aI9H0" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
  <link rel="stylesheet" href="https://mtganalyze.github.io/css/main.css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="https://mtganalyze.github.io/css/pygment_highlights.css" />
  <link rel="stylesheet" href="https://mtganalyze.github.io/css/highlight.min.css" />




<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.1/photoswipe.min.css" integrity="sha256-sCl5PUOGMLfFYctzDW3MtRib0ctyUvI9Qsmq2wXOeBY=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.1/default-skin/default-skin.min.css" integrity="sha256-BFeI1V+Vh1Rk37wswuOYn5lsTcaU96hGaI7OUVCLjPc=" crossorigin="anonymous" />



<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

</head>

  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://mtganalyze.github.io">MTGANALYZE</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/">Blog</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/page/about/">About</a>
            </li>
          
        

        

        
      </ul>
    </div>

    <div class="avatar-container">
      <div class="avatar-img-border">
        
          <a title="MTGANALYZE" href="https://mtganalyze.github.io">
            <img class="avatar-img" src="https://mtganalyze.github.io/img/theorist.jpg" alt="MTGANALYZE" />
          </a>
        
      </div>
    </div>

  </div>
</nav>




    
  
  
  




  

  <header class="header-section ">
    
    <div class="intro-header no-img">
      
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              <h1>Skills and Scores</h1>
                
                
                  <span class="post-meta">
  Posted on September 11, 2017
  
</span>


                
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <p>My brother once told me: “Playing day 2 of a GP is like playing on the Pro Tour – probably even harder”. Neither of us had yet played at the Pro Tour nor made a GP day 2 at that time, but in place of experience we at least had deep respect for the GP day 2 player field. However, regardless of my brother’s statement being right or wrong (it was wrong), the underlying idea is interesting: It must be only the finest players, who are capable of winning at least seven of nine rounds of exhausting tournament Magic. But how skilled are these players really and are they actually much better than the average GP player? Suppose I have something like 50% match win percentage against the overall GP player field, then what would be my match win percentage on day 2?</p>
<p>In this post I address the issue of score-dependent win probabilities, accouting for the two most famous tournament structures: Grand Prix and Pro Tour. My question is: <strong>Given a certain skill level or overall win probability, what is my win probability within a specific score bracket of a PT or GP?</strong></p>
<p>This question contains two puzzles to solve. Firstly, how can “skill” be translated into a win probability and vice versa? Secondly – since the different score brackets at a tournament, e.g. the 4-0 and the 0-4 bracket, provide distinct player fields – how does this translation of skill into win probability differ for those brackets.</p>
<p>To answer these questions, we need a model to quantify (i) the skill of a player and (ii) the match up of different skill levels. Fortunately, such a model is already well know among long-standing Magic players.</p>
<div id="the-elo-rating" class="section level2">
<h2>The ELO rating</h2>
<p>For many years sanctioned tournament Magic used <a href="https://en.wikipedia.org/wiki/Elo_rating_system">ELO rating</a> as a tool to capture the skill level of each single player. Each players rating was thereby represented through a score which increased and decreased with every win and loss, respectively. ELO functions such that each players rating moves in the region around the player’s “true” rating, thus being a rough indicator of the players skill. Eventually, the DCI binned ELO since the rating was also used to hand out, e.g., PT qualifications which somewhat misused ELO as a bonification tool, which led to undesired side effects such as players not wanting to play in order to preserve a high rating. For those of you who didn’t get to know ELO from Magic, ELO also had its 15 minutes of fame during the opening scene in <em>The Social Network</em>: “I need the algorithm!”.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-1"></span>
<img src="../wpt/elo.jpg" alt="Scene from &quot;The Social Network&quot;"  />
<p class="caption">
Figure 1: Scene from “The Social Network”
</p>
</div>
<p>The mathematical principle of the rating system itself is rather straightforward. Given a match between players A and B with ratings <span class="math">\(x_A\)</span> and <span class="math">\(x_B\)</span>, respectively, the ELO system models the win probability of player A as <span class="math">\[p_A = \frac{1}{1 + 10^{-(x_A - x_B) / c}},\]</span> where <span class="math">\(c\)</span> is some scaling constant (The DCI used <span class="math">\(c = 400\)</span>, I believe). From a statistical perspective, this corresponds to the predicted success probability from a logistic regression model using the rating difference (scaled through <span class="math">\(c\)</span>) as its only covariable. Given the outcome of the match, player A’s rating increases by <span class="math">\(K \cdot(1-p_A)\)</span> if he wins the match or decreases by <span class="math">\(K\cdot p_A\)</span> if he loses, where <span class="math">\(K\)</span> is some velocity factor. Thus, assuming the ELO predicted win probability is accurate, the expected rating change of player A is <span class="math">\[\mathbb{E} \left[\Delta x_A\right] = p_A \cdot K(1-p_A) + (1-p_A)\cdot(-Kp_A) = 0.\]</span> Otherwise, if player A is underrated, i.e. its actual win probality is larger than <span class="math">\(p_A\)</span>, then the expected rating change is positive. If player A is overrated the expected rating change is negative. Thus, the rating tends to correct itself.</p>
<p>The relevant property for us is that ELO provides a predictive model for the outcome of any match between two players. All we need is the “true” ELO rating for both of these players. In fact, for our purposes we are interested in the distribution of the “true” ELO ratings within a GP player field, which will be addressed later.</p>
<div id="limitations-of-elo" class="section level4">
<h4>Limitations of ELO</h4>
<p>I put quotation marks around “true” rating, since ELO itself is only model which has a couple weaknesses which need to be mentioned:</p>
<ol style="list-style-type: decimal">
<li><p>If something like a true (fixed) rating of a player exists, it’s actually not possible to infer from solely the current rating of the player, as this is subject of ongoing variation.</p></li>
<li><p>According to ELO, skill is a one-dimensional quantity. This imples, that if player A is better than player B and player B is better than player C, we can derive that player A is better than player C. This might seem natural at first glance. However, Magic is a complex game requiring many different skill sets like analytical thinking, long term planning, and bluffing. Thus, it might be possible that even among different player types there may exist some rock-paper-scissors metagame. This could not be captured by ELO.</p></li>
<li><p>According to ELO, skill is even a metric quantity. This implies that if player A has a 60% win probability against player B and player B has a 60% win probability against player C, then player A must have a 69.2% win probability against player C. In that sense, ELO is a rather stiff model which cannot account for the restricted impact of skill within a partially luck based game like Magic.</p></li>
</ol>
</div>
</div>
<div id="mtgeloproject-data" class="section level2">
<h2>MTGELOPROJECT data</h2>
<p>To appy the ELO model, we need information on the actual ratings of the typical player field within a GP or PT. This is where the work of <a href="http://www.mtgeloproject.net/">MTGELOPROJECT</a> is crucial for us.</p>
<p>MTGELOPROJECT.net is a website created by Adam and Rebecca in order to reunite ELO and Magic: the Gathering. Based on published match results from each Grand Prix and Pro Tour since 2008 (or even earlier), the website retrospectively computes the ELO rating of each player appearing in the data. Scraping these data together sounds like an awful lot of work and it probably is. However, the result is a huge database with insightful statistics, where every player can check her current rating in progress. I highly recommend checking out the site, if you don’t know it yet.</p>
<p>Some time ago, I asked Adam whether he could provide some numbers on the typical rating distribution of a PT and GP player field. He sent me the following numbers (Thanks, Adam!):</p>
<ul>
<li><p>The mean player rating at a Grand Prix is 1554 with lower and upper <a href="https://en.wikipedia.org/wiki/Quartile">quartiles</a> of 1472 and 1606, respectively.</p></li>
<li><p>The mean player rating at a Pro Tour is 1788 with lower and upper quartiles of 1660 and 1918, respectively.</p></li>
</ul>
<p>To give a crude interpretation guideline: within MTGELOPROJECT each player starts at a rating of 1500. Thus, the GP player field is already above average. Also they use a scaling factor of <span class="math">\(c= 1136\)</span>, which means that a rating advantage of 200 points is equivalent to a win probability of 60%. Under the assumption of a normally distributed rating within each tournament player field, I used the interquartile range to roughly compute the corresponding standard deviations which led to the following rating distributions:</p>
<ul>
<li><p>At a Grand Prix the rating is normally distributed with mean 1554 and standard deviation 100.</p></li>
<li><p>At a Pro Tour the rating is normally distributed with mean 1788 and standard deviation 200.</p></li>
</ul>
<p>These are the eventual rating distribution which I applied within the ELO model. Before we come to that, two things should be remarked:</p>
<ol style="list-style-type: decimal">
<li><p>The mean rating within a PT is much higher compared to a GP, which is of course expected.</p></li>
<li><p>The standard deviation, i.e. the rating differences within the player field, are much higher in the PT compared to the GP. I guess this a consequence of many GP players not yet being rated to their true skill within the data, since an accurate rating takes many matches. In contrast, the typical Pro Tour player has already played a few dozens of matches on the GP and PT level, which is why I think that these ratings are roughly accurate. However, this is pure gut feeling and the GP player field might in fact be much more dense with respect to skill level.</p></li>
</ol>
</div>
<div id="simulating-player-fields-by-score-brackets" class="section level2">
<h2>Simulating player fields by score brackets</h2>
<p>It’s time to go off. Using (i) the data on the player field rating distribution and (ii) the ELO model to estimate win probabilities based on those ratings we are now ready to simulate a virtual Grand Prix tournament. Based on this simulation we can draw conclusions on how the rating distribution varies by score bracket as the tournament goes on,</p>
<p>To simulate the tournament, I used the following algorithm which I implemented using <a href="https://www.r-project.org/">R</a>. Here, let <span class="math">\(N\)</span> be the number of tournament players with individual ratings <span class="math">\(x_i\)</span> (<span class="math">\(i=1,\ldots, N\)</span>) drawn independently from a normal distribution with mean 1554 and standard deviation 100 (the GP rating distribution as given above). Let <span class="math">\(r^{(j)}_i\)</span> (<span class="math">\(i=1,\ldots, N\)</span>) denote the number of wins of player <span class="math">\(i\)</span> after round <span class="math">\(j\)</span>. For the sake of definedness we set <span class="math">\(r^{(0)}_i = 0\)</span> for all players. Then we apply the following algorithm:</p>
<ol style="list-style-type: decimal">
<li><p>For <span class="math">\(j = 1, \ldots, 9\)</span> repeat the following steps <strong>2)</strong> to <strong>4)</strong>.</p></li>
<li><p>Sort all players by descending <span class="math">\(r^{(j-1)}_i\)</span> (<em>i.e we sort by score</em>). In case of ties sort randomly within the tie brackets.</p></li>
<li><p>Based on this sorting order, generate pairings by matching player 1 against player 2, player 3 against player 4, and so on. (<em>This procedure basically produces swiss pairings. For simplicity we chose <span class="math">\(N\)</span> to be an even number.</em>)</p></li>
<li><p>For each of the <span class="math">\(N/2\)</span> round matches do the following: let’s denote the two participating players by <span class="math">\(i_1\)</span> and <span class="math">\(i_2\)</span>. We compute the win probability of player <span class="math">\(i_1\)</span> by applying the ELO formula <span class="math">\(p = (1 + 10^{-(x_{i_1} - x_{i_2}) / c})^{-1}\)</span> with <span class="math">\(c = 1136\)</span>. Draw <span class="math">\(Y \sim\)</span> Bern<span class="math">\((p)\)</span> from a Bernoulli distribution (<em>basically we throw a coin that shows head (Y=1) with probability <span class="math">\(p\)</span> and tails (Y=0) with probability <span class="math">\(1-p\)</span></em>). In case of <span class="math">\(Y=1\)</span> we set <span class="math">\(r^{(j+1)}_{i_1} = r^{(j)}_{i_1} + 1\)</span> and <span class="math">\(r^{(j+1)}_{i_2} = r^{(j)}_{i_2}\)</span> (<em>i.e. player <span class="math">\(i_1\)</span> receives a win</em>). In case of <span class="math">\(Y=0\)</span>, update analogeously such that player <span class="math">\(i_2\)</span> receives the win.</p></li>
<li><p>Discard all players with <span class="math">\(r^{(9)}_i &lt; 6\)</span>. (<em>We make a cut after nine rounds and continue only with players who received six wins</em>)</p></li>
<li><p>Using the diminished player field repeat steps <strong>2)</strong> to <strong>4)</strong> for <span class="math">\(j = 9, \ldots, 14\)</span>.</p></li>
</ol>
<p>Note that for this Grand Prix simulation we did not update the rating of each player after each round, since we are only interested in the rating as an indicator for each player’s fixed skill level and not in the rating fluctuations themselves. After the dust is settled, our simulated tournament results contain the number of players within each score bracket after each round and more importantly the ratings of these players within the individual brackets. These bracket specific rating distributions provide a clear picture on how your skill level can affect your tournament score. For instance, let’s look at a snap shot after round nine from a simulation with <span class="math">\(N = 10000000\)</span> players.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-2"></span>
<img src="../wpt/r9snap.jpeg" alt="Rating distribution (given as stacked densities) after round nine of a GP stratified by score."  />
<p class="caption">
Figure 2: Rating distribution (given as stacked densities) after round nine of a GP stratified by score.
</p>
</div>
<p>Here, we see the overall rating distribution of the whole player field and how the player field is decomposed into the different score brackets from zero to nine wins. One can see, that the mean rating of the players with six or more wins – thus reaching day 2 – is at around 1600 (much lower than the mean rating at PT level). The mean rating of the 9-0 players is at around 1650. From another perspective one can also see, that most players rated at 1650 reach day 2 by looking at the “vertical”, i.e. conditional, distribution along the 1650 rating line.</p>
</div>
<div id="the-win-probability-tree" class="section level2">
<h2>The win probability tree</h2>
<p>So far we looked at a model to translate any rating into a win probability against any other opponent rating. Also, due to our simulated tournament based on empirical data we know the players rating distribution within each possible score bracket. By bringing these components together, we are now able to compute the expected win probability of any rated player within a certain score bracket of, e.g., a Grand Prix.</p>
<p>The notation will get a little technical now. To calculate the expected win probability we need to take a look at the simulated player ratings within a specific score bracket. Based on simulated results from above let’s denote by <span class="math">\[\mathcal{R}^{(j)}_w = \{x_i | r^{(j)}_i = w \}\]</span> the rating sample of those players with exactly <span class="math">\(w\)</span> wins after <span class="math">\(j\)</span> rounds. We denote by <span class="math">\[\bar{r}_w^{(j)} = \text{mean}(\mathcal{R}^{(j)}_w),  \quad \text{and} \quad \sigma_w^{(j)} = \text{Var}(\mathcal{R}^{(j)}_w)\]</span> the emprical mean and variance of this rating sample. The expected win probability on a player with rating <span class="math">\(x\)</span> within the score bracket “<span class="math">\(w\)</span> wins after <span class="math">\(j\)</span> rounds” can then be approximated by <span class="math">\[p_w^{(j)} (x) \approx \left|\mathcal{R}^{(j)}_w\right|^{(-1)} \sum_{y \in \mathcal{R}^{(j)}_w}\frac{1}{1 + 10^{-(x - y)/c}}\]</span> <span class="math">\[\approx
\int_{\mathbb{R}} \frac{1}{1 + 10^{-(x - y) / c}} \, \varphi(y, \bar{r}_w^{(j)}, \sigma_w^{(j)}) dy,\]</span> where <span class="math">\(\varphi(\cdot, r, \sigma)\)</span> denotes the density of a normal distribution with mean <span class="math">\(r\)</span> and variance <span class="math">\(\sigma\)</span>. This integral is a rather complicated way to write the solution for the following calculations:</p>
<ol style="list-style-type: decimal">
<li><p>What are frequent ratings within in the score bracket “<span class="math">\(w\)</span> wins after <span class="math">\(j\)</span> rounds”?</p></li>
<li><p>What are the win probabilities against those ratings?</p></li>
<li><p>What is the resulting average win probability?</p></li>
</ol>
<p>This formula gives a translation <em>rating into win probability</em>“. Conversely, for a given score bracket and a given win probability within this bracket we can compute the virtual rating that corresponds to that win probability. To do so, one has to find the rating <span class="math">\(x^*\)</span> such that <span class="math">\[p_w^{(j)} (x^*) = p^*,\]</span> where <span class="math">\(p^*\)</span> is the desired win probability. This equation can be easily solved numerically (read: it cannot be solved easily).</p>
<p>Now it’s time to reap the rewards. By applying a certain rating to all possible score brackets within a GP we obtain all respective win probabilities. As the tournament progresses these score dependent changes in the expected win probability per round thus form a shape of a tree branch as seen below. For this example graphic I set the protagonist’s rating to 1554, i.e. the mean rating in a GP. The underlying rating parameters to produce this tree were those from the MTGELOPROJECT data given above.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-3"></span>
<img src="../wpt/wpt.png" alt="Win probability tree for an average GP player."  />
<p class="caption">
Figure 3: Win probability tree for an average GP player.
</p>
</div>
<p>For each round and score – given trough the number of wins – the tree shows (on the Y-axis) the expected win probability of the protagonist for the following round. In the above graphic the round one win probability is at exactly 50%, since the protagonists rating equals the mean rating in the player field. However, in round six at a score of 5-0 the expected win probability of the protagonist would be 47.5% due to the more skilled opponents within this bracket.</p>
<p>Since it’s not convenient to show all win probability trees (WPTs) for a large sprectrum of protagonist ratings and tournament forms within this post, I wrote a web application using <a href="https://shiny.rstudio.com/">R shiny</a> in order to compute the WPT for any desired parameters. This WPT app can be found here:</p>
<p><strong>[<a href="https://mtganalyze.shinyapps.io/wp_tree/" class="uri">https://mtganalyze.shinyapps.io/wp_tree/</a>]</strong></p>
<p>As a user one can choose the tournament structure (GP or PT), the overall win probability against the field, and the skill density. A normal skill density corresponds to that from the MTGELOPROJECT data, whereas the dense and diverse skill density assume a smaller and larger variance in the rating distribution, respectively. As said above, for GPs I can imagine that the diverse skill density is closer to the true distribution. The app then computes the virtual MTGELOPROJECT rating and the corresponding WPT. One approach might be to chose the win probability such that it matches your own WPT rating. Just give it a try.</p>
</div>
<div id="end-of-turn" class="section level2">
<h2>End of turn</h2>
<p>I hope you enjoyed this first post. Maybe even you found it useful. I am very eager to hear your feedback. Do you like the idea of the WPT or do you think its abstract nonsense? Was the presentation too technical, too lengthy, too boring? I am happy to adjust for further content.</p>
<p>Next time, I will present an use case of the WPT, that especially for tournament players might be interesting. If you don’t want to miss it, follow me on <a href="https://twitter.com/mtganalyze">twitter</a> or just come back regularly.</p>
</div>

      </article>

      <ul class="pager blog-pager">
        
          <li class="previous">
            <a href="https://mtganalyze.github.io/post/who-am-i/" data-toggle="tooltip" data-placement="top" title="Who am I?">&larr; Previous Post</a>
          </li>
        
        
      </ul>

      
        
          <div class="disqus-comments">
            <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "mtganalyze" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
          </div>
        
      

    </div>
  </div>
</div>

    <footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
                <a href="mailto:mtganalyze@gmail.com" title="Email me">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://github.com/mtganalyze" title="GitHub">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://twitter.com/mtganalyze" title="Twitter">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
        </ul>
        <p class="credits copyright text-muted">
          
            
              Felix Weidemann
                      
          
          
          &nbsp;&bull;&nbsp;
          2017

          
            &nbsp;&bull;&nbsp;
            <a href="https://mtganalyze.github.io">MTGANALYZE</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="http://gohugo.io">Hugo v0.26</a> powered &nbsp;&bull;&nbsp; Theme by <a href="http://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a> adapted to <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a>
          
        </p>
      </div>
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js" integrity="sha384-/y1Nn9+QQAipbNQWU65krzJralCnuOasHncUFXGkdwntGeSvQicrYkiUBwsgUqc1" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js" integrity="sha384-dq1/gEHSxPZQ7DdrM82ID4YVol9BYyU7GbWlIwnwyPzotpoc57wDw/guX8EaYGPx" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="https://mtganalyze.github.io/js/main.js"></script>
<script src="https://mtganalyze.github.io/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> renderMathInElement(document.body); </script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.1/photoswipe.min.js" integrity="sha256-UplRCs9v4KXVJvVY+p+RSo5Q4ilAUXh7kpjyIP5odyc=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.1/photoswipe-ui-default.min.js" integrity="sha256-PWHOlUzc96pMc8ThwRIXPn8yH4NOLu42RQ0b9SpnpFk=" crossorigin="anonymous"></script>
<script src="https://mtganalyze.github.io/js/load-photoswipe.js"></script>




  </body>
</html>

